{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35aebf2e-0635-4fef-bc9a-877b6a20fb13",
   "metadata": {},
   "source": [
    "# Predicting Credit Card (CC) Approvals with Machine Learning\n",
    "\n",
    "## Background tale\n",
    "\n",
    "Commercial banks receive _a lot_ of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this workbook, you will build an automatic credit card approval predictor using machine learning techniques, just like real banks do.\n",
    "\n",
    "## The Data\n",
    "\n",
    "The data is a small subset of the Credit Card Approval dataset from the UCI Machine Learning Repository showing the credit card applications a bank receives. This dataset has been loaded as a `pandas` DataFrame called `cc_apps`. The last column in the dataset is the target value.\n",
    "\n",
    "## Goal\n",
    "\n",
    "A ML model for prediction of CC approvals with an accuracy of at least 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c87400",
   "metadata": {},
   "source": [
    "## Getting to know the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e86b1e8-a3fa-4b09-982f-795f218bd1a6",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 550,
      "tableState": {},
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting to know the data:\n",
      "\n",
      "----------------------------------\n",
      "cc_apps shape: (690, 14)\n",
      "----------------------------------\n",
      "cc_apps columns:\n",
      " Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], dtype='int64')\n",
      "----------------------------------\n",
      "cc_apps dtypes:\n",
      " 0      object\n",
      "1      object\n",
      "2     float64\n",
      "3      object\n",
      "4      object\n",
      "5      object\n",
      "6      object\n",
      "7     float64\n",
      "8      object\n",
      "9      object\n",
      "10      int64\n",
      "11     object\n",
      "12      int64\n",
      "13     object\n",
      "dtype: object\n",
      "----------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       690 non-null    object \n",
      " 1   1       690 non-null    object \n",
      " 2   2       690 non-null    float64\n",
      " 3   3       690 non-null    object \n",
      " 4   4       690 non-null    object \n",
      " 5   5       690 non-null    object \n",
      " 6   6       690 non-null    object \n",
      " 7   7       690 non-null    float64\n",
      " 8   8       690 non-null    object \n",
      " 9   9       690 non-null    object \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    object \n",
      " 12  12      690 non-null    int64  \n",
      " 13  13      690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(10)\n",
      "memory usage: 75.6+ KB\n",
      "cc_apps info:\n",
      " None\n",
      "----------------------------------\n",
      "cc_apps head:\n",
      "   0      1      2  3  4  5  6     7  8  9   10 11   12 13\n",
      "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  g    0  +\n",
      "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  g  560  +\n",
      "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  g  824  +\n",
      "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  g    3  +\n",
      "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  s    0  +\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the dataset\n",
    "cc_apps = pd.read_csv(\"cc_approvals.data\", header=None)\n",
    "print('Getting to know the data:\\n')\n",
    "print('----------------------------------')\n",
    "print('cc_apps shape:', cc_apps.shape)\n",
    "print('----------------------------------')\n",
    "print('cc_apps columns:\\n', cc_apps.columns)\n",
    "print('----------------------------------')\n",
    "print('cc_apps dtypes:\\n', cc_apps.dtypes)\n",
    "print('----------------------------------')\n",
    "print('cc_apps info:\\n', cc_apps.info())\n",
    "print('----------------------------------')\n",
    "print('cc_apps head:\\n', cc_apps.head())\n",
    "print('----------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2877755-2ab1-4719-b100-663d8ef82688",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 2217,
    "lastExecutedAt": 1745193999319,
    "lastExecutedByKernel": "fce28d0a-0849-4098-bcb2-148b0468e0b7",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "cc_apps.info()"
   },
   "outputs": [],
   "source": [
    "# Let's first provide a good name for the columns. The last one is the target\n",
    "cc_apps.columns = ['col_' + str(i) for i in range(cc_apps.shape[1] - 1)] + ['target']\n",
    "# Let's also map the target to be 1 for + and 0 for -\n",
    "cc_apps['target'] = cc_apps['target'].map({'+': 1, '-': 0}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491baf7c",
   "metadata": {},
   "source": [
    "## Building the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(model, num_cols: list, cat_cols: list) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Creates a pipeline for the given model. This function accounts for the model's scaling sensitivity, that is, it doesn't apply the StandardScaler to models that are not sensitive to scaling.\n",
    "    \n",
    "    Args:\n",
    "        model (class object): The model to be used in the pipeline.\n",
    "        \n",
    "    Returns:\n",
    "        pipeline (Pipeline): The constructed pipeline.\n",
    "    \"\"\"\n",
    "    # Check the scaling sensitivity\n",
    "    is_scale_sensitive = isinstance(model, (LogisticRegression, RidgeClassifier, SVC, KNeighborsClassifier))\n",
    "    \n",
    "    transformers = []\n",
    "    \n",
    "    if is_scale_sensitive:\n",
    "        transformers.append(\n",
    "            ('num', StandardScaler(), num_cols)\n",
    "        )\n",
    "    else:\n",
    "        transformers.append(\n",
    "            ('num', 'passthrough', num_cols)\n",
    "        )\n",
    "    \n",
    "    transformers.append(\n",
    "        ('cats', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=transformers)\n",
    "    \n",
    "    return Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "def apply_grid_search(models: list):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for model, param_grid in models:\n",
    "        pipeline = build_pipeline(model, num_cols, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de931c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the GridSearch\n",
    "\n",
    "models = [\n",
    "    (LogisticRegression(), {'model__C': [.001, .01, .1, 1, 10,100],\n",
    "                            'model__max_iter': [100, 500, 1000],\n",
    "                            'model__penalty': ['l1', 'l2', 'none'],\n",
    "                            'model__solver': ['liblinear', 'libfgs']}),\n",
    "    (RidgeClassifier(), {}),\n",
    "    (DecisionTreeClassifier(), {}),\n",
    "    (RandomForestClassifier(), {}),\n",
    "    (GradientBoostingClassifier(), {}),\n",
    "    (SVC(), {}),\n",
    "    (GaussianNB(), {}),\n",
    "    (KNeighborsClassifier(), {})\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
